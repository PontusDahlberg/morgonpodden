#!/usr/bin/env python3
"""
MULTI-AGENT NEWS CURATION SYSTEM
================================
Orchestrator-baserat system med specialiserade agenter f√∂r att s√§kerst√§lla
kvalitet, relevans och balans i nyhetsurvalet.

AGENTER:
1. NewsScraperAgent - Scraper och kategoriserar nyheter
2. RelevanceAgent - Bed√∂mer relevans mot kriterier (klimat/milj√∂/AI/tech)
3. FactCheckAgent - Verifierar fakta och rimlighetskontroll
4. BalanceAgent - S√§kerst√§ller r√§tt f√∂rdelning (50%+ klimat/milj√∂)
5. Orchestrator - Koordinerar alla agenter och fattar slutgiltiga beslut

KVALITETSKRITERIER:
- Svenska klimat/milj√∂-nyheter prioriteras h√∂gst
- Globala klimat/milj√∂-nyheter sekund√§rt
- Tech/AI endast om klimat/milj√∂-relevans ELLER h√∂gkvalitativa tech-nyheter
- F√ñRBJUDET: Gaming, underh√•llning, produktreklam, sociala medier
- Faktakontroll: Rimlighetsbed√∂mning av siffror och p√•st√•enden
"""

import json
import logging
import asyncio
from typing import List, Dict, Optional
from datetime import datetime
from dataclasses import dataclass
from enum import Enum

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class NewsCategory(Enum):
    """Nyhetskategorier med prioritet"""
    CLIMATE_SWEDEN = "climate_sweden"  # H√∂gst prioritet
    CLIMATE_GLOBAL = "climate_global"  # H√∂g prioritet
    ENVIRONMENT_SWEDEN = "environment_sweden"  # H√∂g prioritet
    ENVIRONMENT_GLOBAL = "environment_global"  # Medel prioritet
    TECH_CLIMATE = "tech_climate"  # Medel prioritet (tech med klimatkoppling)
    TECH_AI = "tech_ai"  # L√•g prioritet
    TECH_GENERAL = "tech_general"  # Mycket l√•g prioritet
    IRRELEVANT = "irrelevant"  # Exkluderas


@dataclass
class NewsArticle:
    """Nyhetsobjekt med metadata"""
    source: str
    title: str
    content: str
    link: str
    category: Optional[NewsCategory] = None
    relevance_score: float = 0.0
    fact_check_passed: bool = False
    fact_check_notes: str = ""
    geographic_region: str = ""  # Sverige, Norden, Europa, Global


class NewsScraperAgent:
    """
    Agent 1: Scraper och kategoriserar nyheter
    Ansvarar f√∂r att identifiera kategori och geografisk region
    """
    
    CLIMATE_KEYWORDS = [
        'klimat', 'climate', 'v√§der', 'weather', 'CO2', 'koldioxid', 
        'utsl√§pp', 'emissions', 'uppv√§rmning', 'global warming',
        'COP', 'IPCC', 'Paris-avtalet', 'klimatm√•l', 'fossilfri',
        'f√∂rnybar energi', 'renewable', 'vindkraft', 'solkraft',
        'solenergi', 'k√§rnkraft', 'nuclear', 'energi', 'energy'
    ]
    
    ENVIRONMENT_KEYWORDS = [
        'milj√∂', 'environment', 'h√•llbarhet', 'sustainability',
        'natur', 'nature', 'ekosystem', 'ecosystem', 'biologisk m√•ngfald',
        'biodiversity', '√•tervinning', 'recycling', 'cirkul√§r ekonomi',
        'f√∂rorening', 'pollution', 'skog', 'forest', 'hav', 'ocean',
        'vatten', 'water', 'luft', 'air quality', 'naturv√•rd',
        'skyddad', 'arter', 'species'
    ]
    
    TECH_CLIMATE_KEYWORDS = [
        'elbilar', 'electric vehicle', 'EV', 'batterilagring',
        'energieffektiv', 'smart grid', 'v√§rmepump', 'heat pump',
        'koldioxidavskiljning', 'carbon capture', 'gr√∂n tech',
        'clean tech', 'klimatteknik', 'climate tech'
    ]
    
    IRRELEVANT_KEYWORDS = [
        'gaming', 'game', 'spel', 'dataspel', 'esport',
        'disney', 'netflix', 'film', 'movie', 'serie', 'TV show',
        'streaming', 'xbox', 'playstation', 'nintendo',
        'iphone', 'galaxy', 'pixel', 'macbook', 'ipad',
        'deals', 'sale', 'rabatt', 'k√∂pguide', 'test av',
        'best movies', 'best shows', 'celebrity', 'k√§ndis'
    ]
    
    SWEDISH_INDICATORS = [
        'sverige', 'swedish', 'stockholm', 'g√∂teborg', 'malm√∂',
        'riksdag', 'regering', 'statsminister', 'milj√∂minister',
        'naturv√•rdsverket', 'smhi', 'sgu', 'havs- och vattenmyndigheten'
    ]
    
    def categorize(self, article: NewsArticle) -> NewsArticle:
        """Kategorisera artikel baserat p√• inneh√•ll"""
        text = f"{article.title} {article.content}".lower()
        
        # Kolla om irrelevant f√∂rst
        if any(keyword in text for keyword in self.IRRELEVANT_KEYWORDS):
            article.category = NewsCategory.IRRELEVANT
            logger.info(f"[SCRAPER] ‚ùå IRRELEVANT: {article.title}")
            return article
        
        # Identifiera geografisk region
        is_swedish = any(indicator in text for indicator in self.SWEDISH_INDICATORS)
        article.geographic_region = "Sverige" if is_swedish else "Global"
        
        # Kategorisera efter inneh√•ll
        has_climate = any(kw in text for kw in self.CLIMATE_KEYWORDS)
        has_environment = any(kw in text for kw in self.ENVIRONMENT_KEYWORDS)
        has_tech_climate = any(kw in text for kw in self.TECH_CLIMATE_KEYWORDS)
        
        if has_climate and is_swedish:
            article.category = NewsCategory.CLIMATE_SWEDEN
        elif has_climate:
            article.category = NewsCategory.CLIMATE_GLOBAL
        elif has_environment and is_swedish:
            article.category = NewsCategory.ENVIRONMENT_SWEDEN
        elif has_environment:
            article.category = NewsCategory.ENVIRONMENT_GLOBAL
        elif has_tech_climate:
            article.category = NewsCategory.TECH_CLIMATE
        elif 'ai' in text or 'artificial intelligence' in text or 'maskininl√§rning' in text:
            article.category = NewsCategory.TECH_AI
        else:
            article.category = NewsCategory.TECH_GENERAL
        
        logger.info(f"[SCRAPER] ‚úÖ {article.category.value.upper()} ({article.geographic_region}): {article.title[:60]}")
        return article


class RelevanceAgent:
    """
    Agent 2: Bed√∂mer relevans mot MMM:s kriterier
    Ger relevance_score 0-100
    """
    
    def evaluate(self, article: NewsArticle) -> NewsArticle:
        """Betygs√§tt relevans f√∂r MMM Senaste Nytt"""
        
        # Irrelevanta artiklar f√•r 0
        if article.category == NewsCategory.IRRELEVANT:
            article.relevance_score = 0
            return article
        
        # Scoring baserat p√• kategori och geografi
        base_scores = {
            NewsCategory.CLIMATE_SWEDEN: 100,
            NewsCategory.ENVIRONMENT_SWEDEN: 95,
            NewsCategory.CLIMATE_GLOBAL: 90,
            NewsCategory.ENVIRONMENT_GLOBAL: 85,
            NewsCategory.TECH_CLIMATE: 70,
            NewsCategory.TECH_AI: 40,
            NewsCategory.TECH_GENERAL: 20,
        }
        
        article.relevance_score = base_scores.get(article.category, 0)
        
        # Boost f√∂r svenska nyheter
        if article.geographic_region == "Sverige":
            article.relevance_score += 5
        
        # Penalty f√∂r vissa k√§llor som ofta har irrelevanta nyheter
        if 'wired' in article.source.lower() or 'verge' in article.source.lower():
            if article.category in [NewsCategory.TECH_GENERAL, NewsCategory.TECH_AI]:
                article.relevance_score -= 20
        
        logger.info(f"[RELEVANCE] Score {article.relevance_score}: {article.title[:60]}")
        return article


class FactCheckAgent:
    """
    Agent 3: Faktakontroll och rimlighetsbed√∂mning
    Anv√§nder AI f√∂r att bed√∂ma om p√•st√•enden √§r rimliga
    """
    
    UNREALISTIC_PATTERNS = [
        (r'hundred.*dead|hundreds.*killed', r'thousand|tusen', 
         "Verkar underskatta d√∂dsfall - b√∂r vara tusentals, inte hundratals"),
        (r'million.*affected', r'thousand|tusen', 
         "Verkar √∂verskatta p√•verkan - troligen tusentals, inte miljoner"),
        (r'100%|hundra procent', r'', 
         "100% p√•st√•enden √§r ofta orealistiska"),
    ]
    
    async def verify(self, article: NewsArticle) -> NewsArticle:
        """Verifiera fakta och rimlighet"""
        text = f"{article.title} {article.content}".lower()
        
        # Grundl√§ggande rimlighetskontroller
        issues = []
        
        # Kolla efter orimliga siffror
        import re
        
        # Sudan-specifik check (exempel fr√•n dagens problem)
        if 'sudan' in text:
            if 'hundred' in text and 'dead' in text:
                if 'thousand' not in text:
                    issues.append("‚ö†Ô∏è Sudan-konflikten: 'Hundratals' d√∂da verkar vara en underskattning. Troligen tusentals.")
        
        # Generella checks
        for pattern, counter_pattern, message in self.UNREALISTIC_PATTERNS:
            if re.search(pattern, text):
                if counter_pattern and not re.search(counter_pattern, text):
                    issues.append(message)
        
        if issues:
            article.fact_check_passed = False
            article.fact_check_notes = " | ".join(issues)
            logger.warning(f"[FACT-CHECK] ‚ö†Ô∏è {article.title[:60]}")
            for issue in issues:
                logger.warning(f"              {issue}")
        else:
            article.fact_check_passed = True
            logger.info(f"[FACT-CHECK] ‚úÖ {article.title[:60]}")
        
        return article


class BalanceAgent:
    """
    Agent 4: S√§kerst√§ller r√§tt √§mnesbalans
    Minst 50% klimat/milj√∂, max 50% tech/AI
    """
    
    def __init__(self, target_climate_percent: int = 60):
        self.target_climate_percent = target_climate_percent
    
    def balance(self, articles: List[NewsArticle], target_count: int = 10) -> List[NewsArticle]:
        """V√§lj balanserad upps√§ttning artiklar"""
        
        # Filtrera bort irrelevanta och fact-check-failade
        valid_articles = [
            a for a in articles 
            if a.category != NewsCategory.IRRELEVANT and a.fact_check_passed
        ]
        
        # Sortera efter relevans
        valid_articles.sort(key=lambda x: x.relevance_score, reverse=True)
        
        # Gruppera efter typ
        climate_env = [
            a for a in valid_articles 
            if a.category in [
                NewsCategory.CLIMATE_SWEDEN, NewsCategory.CLIMATE_GLOBAL,
                NewsCategory.ENVIRONMENT_SWEDEN, NewsCategory.ENVIRONMENT_GLOBAL,
                NewsCategory.TECH_CLIMATE
            ]
        ]
        
        tech_ai = [
            a for a in valid_articles
            if a.category in [NewsCategory.TECH_AI, NewsCategory.TECH_GENERAL]
        ]
        
        # Ber√§kna m√•lf√∂rdelning
        climate_target = int(target_count * self.target_climate_percent / 100)
        tech_target = target_count - climate_target
        
        # V√§lj artiklar
        selected = climate_env[:climate_target] + tech_ai[:tech_target]
        
        # Om vi inte har tillr√§ckligt med klimat-artiklar, fyll p√• med tech
        if len(selected) < target_count:
            remaining = target_count - len(selected)
            more_tech = [a for a in tech_ai if a not in selected][:remaining]
            selected.extend(more_tech)
        
        logger.info(f"[BALANCE] Valde {len([a for a in selected if a.category in [NewsCategory.CLIMATE_SWEDEN, NewsCategory.CLIMATE_GLOBAL, NewsCategory.ENVIRONMENT_SWEDEN, NewsCategory.ENVIRONMENT_GLOBAL, NewsCategory.TECH_CLIMATE]])} klimat/milj√∂ och {len([a for a in selected if a.category in [NewsCategory.TECH_AI, NewsCategory.TECH_GENERAL]])} tech/AI")
        
        return selected[:target_count]


class NewsOrchestrator:
    """
    HUVUDORCHESTRATOR
    Koordinerar alla agenter och fattar slutgiltiga beslut
    """
    
    def __init__(self):
        self.scraper = NewsScraperAgent()
        self.relevance = RelevanceAgent()
        self.fact_checker = FactCheckAgent()
        self.balance = BalanceAgent(target_climate_percent=60)
    
    async def process_articles(self, raw_articles: List[Dict]) -> List[NewsArticle]:
        """
        Huvudprocess: K√∂r alla artiklar genom agent-pipeline
        """
        logger.info(f"\n{'='*60}")
        logger.info(f"üéØ ORCHESTRATOR: Startar bearbetning av {len(raw_articles)} artiklar")
        logger.info(f"{'='*60}\n")
        
        # Konvertera till NewsArticle-objekt
        articles = [
            NewsArticle(
                source=a.get('source', ''),
                title=a.get('title', ''),
                content=a.get('content', ''),
                link=a.get('link', '')
            )
            for a in raw_articles
        ]
        
        # Steg 1: Kategorisering
        logger.info("\nüìã STEG 1: KATEGORISERING")
        logger.info("-" * 60)
        articles = [self.scraper.categorize(a) for a in articles]
        
        # Steg 2: Relevansbed√∂mning
        logger.info("\n‚≠ê STEG 2: RELEVANSBED√ñMNING")
        logger.info("-" * 60)
        articles = [self.relevance.evaluate(a) for a in articles]
        
        # Steg 3: Faktakontroll
        logger.info("\nüîç STEG 3: FAKTAKONTROLL")
        logger.info("-" * 60)
        articles = await asyncio.gather(*[self.fact_checker.verify(a) for a in articles])
        
        # Steg 4: Balansering
        logger.info("\n‚öñÔ∏è  STEG 4: BALANSERING")
        logger.info("-" * 60)
        selected = self.balance.balance(articles, target_count=10)
        
        # Slutrapport
        logger.info(f"\n{'='*60}")
        logger.info(f"‚úÖ ORCHESTRATOR: Slutresultat")
        logger.info(f"{'='*60}")
        logger.info(f"Totalt bearbetade: {len(articles)}")
        logger.info(f"Irrelevanta: {len([a for a in articles if a.category == NewsCategory.IRRELEVANT])}")
        logger.info(f"Fact-check failed: {len([a for a in articles if not a.fact_check_passed and a.category != NewsCategory.IRRELEVANT])}")
        logger.info(f"Valda f√∂r podcast: {len(selected)}")
        
        logger.info(f"\nüìä F√ñRDELNING AV VALDA:")
        for category in NewsCategory:
            count = len([a for a in selected if a.category == category])
            if count > 0:
                logger.info(f"  ‚Ä¢ {category.value}: {count}")
        
        logger.info(f"\nüìç GEOGRAFISK F√ñRDELNING:")
        sweden_count = len([a for a in selected if a.geographic_region == "Sverige"])
        logger.info(f"  ‚Ä¢ Sverige: {sweden_count}")
        logger.info(f"  ‚Ä¢ Global: {len(selected) - sweden_count}")
        
        return selected


async def main():
    """Test av agent-systemet"""
    # Exempel p√• test med dagens artiklar
    with open('episode_articles_20251107_040743.json', 'r', encoding='utf-8') as f:
        raw_articles = json.load(f)
    
    orchestrator = NewsOrchestrator()
    selected = await orchestrator.process_articles(raw_articles)
    
    print("\n" + "="*80)
    print("SLUTGILTIGT URVAL F√ñR PODCAST:")
    print("="*80)
    for i, article in enumerate(selected, 1):
        print(f"\n{i}. [{article.category.value}] {article.title}")
        print(f"   Relevans: {article.relevance_score}/100")
        print(f"   K√§lla: {article.source}")
        print(f"   Region: {article.geographic_region}")
        if article.fact_check_notes:
            print(f"   ‚ö†Ô∏è  {article.fact_check_notes}")


if __name__ == "__main__":
    asyncio.run(main())
